---
title: "[KAIST AI 교육 :: 데이터 분석 및 예측] 1"
date: 2020-08-18 20:15:30 -0400
categories: DeepLearning DataAnalyze
---
# 선형회귀와 경사하강법

<hr/>
<div style = "font-size :0.7em">
<p>
머신러닝이란?<br/><br/>
data가 주어졌을 때 data를 구분하는 하나의 식을 만들어 내고, 이 식을 통해 어떠한 값을 예측하는 것이다.<br/><br/>
이 때 식은 점들을 통과하는 graph거나 아니면 영역을 구분짓는 graph가 되기도 한다.<br/><br/>

즉, 무수한 data를 통해 하나의 식을 도출하는 것이 핵심이다 <br/><br/>
이 때 우리는 '이 식이 대충 어떠한 형태를 띌 것이다'라고 추정을 하고 시작한다.<br/><br/>

구해질 식이 1차함수일지 2차함수일지 3차함수일지 아니면 엄청 복잡한식일지 이정도는 우리가 해야한다는 것.<br/><br/>
더 쉽게 말하자면  ax+b일지 ax^+bx+c일지 우리가 형태는 잡아주고 a b..의 상수들은 컴퓨터가 data들을 대입하면서 찾아내게 한다는 것이다.<br/><br/>
이 때 저 식을 가설(Hypothesis)이라하며 H(x)로 표현한다.<br/><br/> 

</p>
<hr/>
<p>
오늘 다룰 것은 머신러닝의 가장 기초적인 추론법인 선형회귀.<br/><br/>

공대생이라면 절대 모를 리 없는 '선형'이지만 요즘 머신러닝이 인기가 많기에 비전공자들도
머신러닝을 하기에 조금 설명하자면..<br/><br/>

선형(linear). 이름에서 유추 할 수 있듯 하나의 직선으로 표현되는 것이고 그러한 성질을 띄는 것을 선형성이라 한다.<br/><br/>

엄밀히 이야기 하자면 이론적인 선형성은 vector에서 이야기 되며, vector에 특징 답게 기울기만 같다면 같은 걸로 퉁친다.<br/><br/>

걍 y절편, 출발점, 길이 이딴거 때려친다는 소리다.<br/><br/>

그냥 간략하게 우리가 중학교에서 배우는 1차함수인 y = ax꼴을 생각하면 된다.<br/><br/><br/>

<i>선형성은 중첩의 원리를 보장 (ax1+bx2 = a(x1+x2).가 통한다.)하며 중첩의 원리가 통하는 식들은 직관적이고 예측 가능하다.<br/>

이 때문에 논문들에서 내가 만든 모델이 선형성을 띈다는 것을 증명하는데 하루종일 써내리는 이유기도 하다.</i><br/><br/><br/>


</p>
<hr/>
<p>
이제 선형회귀에 대해 다시 설명하자면 선형식인 H(x)를 찾아내는 것이다.
그리고 H(x)가 x하나에 대해서 변한다면 단순 회귀 분석, 둘 이상이라면 다중 회귀 분석이라 한다.<br/>

단순 : H(x) = Wx1+b<br/>
다중 : H(x) = W1x1 + W2x2 +....Wnxn+b<br/>

<br/><br/>

</p>
<div/>